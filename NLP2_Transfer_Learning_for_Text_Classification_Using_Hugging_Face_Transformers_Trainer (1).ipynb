{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQqHYsWVTV6D"
   },
   "source": [
    "Fine-tuning a pretrained transformer BERT model for customized sentiment analysis using transformer PyTorch Trainer from Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O1mw8kqWC0H"
   },
   "source": [
    "# Step 0: Transfer Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vtKX1QdQbP2"
   },
   "source": [
    "In step 0, we will talk about how transfer learning works.\n",
    "\n",
    "Transfer learning is a machine learning technique that reuses a pretrained large deep learning model on a new task. It usually includes the following steps:\n",
    "1. Select a pretrained model that is suitable for the new task. For example, if the new task includes text from different languages, a multi-language pretrained model needs to be selected.\n",
    "2. Keep all the weights and biases from the pretrained model except for the output layer. This is because the output layer for the pretrained model is for the pretrained tasks and it needs to be replaced with the new task.\n",
    "3. Feed randomly initialize weights and biases into the new head of the new task. For a sentiment analysis transfer learning (aka fine-tuning) model on a pretrained BERT model, we will remove the head that classifies mask words, and replace it with the two sentiment analysis labels, positive and negative.\n",
    "4. Retrain the model for the new task with the new data, utilizing the pretrained weights and biases. Because the weights and biases store the knowledge learned from the pretrained model, the fine-tuned transfer learning model can build on that knowledge and does not need to learn from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKQQXSGszh8z"
   },
   "source": [
    "# Step 1: Install And Import Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2NeMSfdXOAD"
   },
   "source": [
    "In step 1, we will install and import python libraries.\n",
    "\n",
    "Firstly, let's install `transformers`, `datasets`, and `evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zhlCxlYWFCHw",
    "outputId": "26cc5135-0022-405a-f966-ec54730a3150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNcfm6_xfvK4"
   },
   "source": [
    "After installing the python packages, we will import the python libraries.\n",
    "* `pandas` and `numpy` are imported for data processing.\n",
    "* `tensorflow` and `transformers` are imported for modeling.\n",
    "* `Dataset` is imported for the Hugging Face dataset format.\n",
    "* `evaluate` is imported for model performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4diGKC0ZgETX"
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n",
    "\n",
    "# Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# Model performance evaluation\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zsSYMz72Pj3"
   },
   "source": [
    "# Step 2: Download And Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf9nPi8-2UyC"
   },
   "source": [
    "The second step is to download and read the dataset.\n",
    "\n",
    "The UCI Machine Learning Repository has the review data from three websites: imdb.com, amazon.com, and yelp.com. We will use the review data from amazon.com for this tutorial. Please follow these steps to download the data.\n",
    "1. Go to: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "2. Click \"Data Folder\"\n",
    "3. Download \"sentiment labeled sentences.zip\"\n",
    "4. Unzip \"sentiment labeled sentences.zip\"\n",
    "5. Copy the file \"amazon_cells_labelled.txt\" to your project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_LPDCa2YTn"
   },
   "source": [
    "Those who are using Google Colab for this analysis need to mount Google Drive to read the dataset. You can ignore the code below if you are not using Google Colab.\n",
    "* `drive.mount` is used to mount to the Google drive so the colab notebook can access the data on the Google drive.\n",
    "* `os.chdir` is used to change the default directory on Google drive. I set the default directory to the folder where the review dataset is saved.\n",
    "* `!pwd` is used to print the current working directory.\n",
    "\n",
    "Please check out [Google Colab Tutorial for Beginners](https://medium.com/towards-artificial-intelligence/google-colab-tutorial-for-beginners-834595494d44) for details about using Google Colab for data science projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vD9lxrv52eKU",
    "outputId": "5b99ee95-6d4a-41ca-ac26-48063d59df13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/contents/nlp\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Change directory\n",
    "import os\n",
    "os.chdir(\"drive/My Drive/contents/nlp\")\n",
    "\n",
    "# Print out the current directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKQzJp0V3I2Y"
   },
   "source": [
    "Now let's read the data into a `pandas` dataframe and see what the dataset looks like.\n",
    "\n",
    "The dataset has two columns. One column contains the reviews and the other column contains the sentiment label for the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iHeaTdXC3KF0",
    "outputId": "414de1e7-dbaf-48be-bcb3-143bee307c14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"amz_review\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"The range is very decent, I've been able to roam around my house with the phone in the living room with no reception/sound quality issues.\",\n          \"The reception is excellent!\",\n          \"I would have given no star if I was able.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "amz_review"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ec0de382-5b91-487b-b576-7365ce41be43\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec0de382-5b91-487b-b576-7365ce41be43')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ec0de382-5b91-487b-b576-7365ce41be43 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ec0de382-5b91-487b-b576-7365ce41be43');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-850eb559-8176-4963-9887-df05c7706515\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-850eb559-8176-4963-9887-df05c7706515')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-850eb559-8176-4963-9887-df05c7706515 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "amz_review = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', names=['review', 'label'])\n",
    "\n",
    "# Take a look at the data\n",
    "amz_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMI16IQ7Nnj6"
   },
   "source": [
    "`.info` helps us to get information about the dataset.\n",
    "\n",
    "From the output, we can see that this data set has 1000 records and no missing data. The `review` column is the `object` type and the `label` column is the `int64` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FhFS5XPxNoRw",
    "outputId": "ca6b8fc8-c979-4739-a657-e4cd75dbe87d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  1000 non-null   object\n",
      " 1   label   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset information\n",
    "amz_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VMuoMFwnMbV"
   },
   "source": [
    "The label value of 0 represents negative reviews and the label value of 1 represents positive reviews. The dataset has 500 positive reviews and 500 negative reviews. It is well-balanced, so we can use  accuracy as the metric to evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "16rB8tdEaYX1",
    "outputId": "87a26dba-c06e-4e2a-ab79-ffe6804b5957"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "label\n",
       "0    500\n",
       "1    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the label distribution\n",
    "amz_review['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2rfMma3Smh7"
   },
   "source": [
    "# Step 3: Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM7ZEjUCVyv3"
   },
   "source": [
    "In step 3, we will split the dataset and have 80% as the training dataset and 20% as the testing dataset.\n",
    "\n",
    "Using the `sample` method, we set `frac=0.8`, which randomly samples 80% of the data. `random_state=42` ensures that the sampling result is reproducible.\n",
    "\n",
    "Dropping the `train_data` from the review dataset gives us the rest 20% of the data, which is our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "PaFydZD5BHqO",
    "outputId": "4863d196-f985-443e-cf9a-d37b622ddceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 800 records.\n",
      "The testing dataset has 200 records.\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_data = amz_review.sample(frac=0.8, random_state=42)\n",
    "\n",
    "# Testing dataset\n",
    "test_data = amz_review.drop(train_data.index)\n",
    "\n",
    "# Check the number of records in training and testing dataset.\n",
    "print(f'The training dataset has {len(train_data)} records.')\n",
    "print(f'The testing dataset has {len(test_data)} records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP1XBRjRWtfX"
   },
   "source": [
    "After the train test split, there are 800 reviews in the training dataset and 200 reviews in the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7_KrZL1E5pH"
   },
   "source": [
    "# Step 4: Convert Pandas Dataframe to Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wL7euXiEwEw"
   },
   "source": [
    "In step 4, the training and the testing datasets will be converted from pandas dataframe to Hugging Face Dataset format.\n",
    "\n",
    "Hugging Face Dataset objects are memory-mapped on drive, so they are not limited by RAM memory, which is very helpful for processing large datasets.\n",
    "\n",
    "We use `Dataset.from_pandas` to convert a pandas dataframe to a Hugging Face Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JM0CjSK7DFWi"
   },
   "outputs": [],
   "source": [
    "# Convert pyhton dataframe to Hugging Face arrow dataset\n",
    "hg_train_data = Dataset.from_pandas(train_data)\n",
    "hg_test_data = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljaWzXG-PEpM"
   },
   "source": [
    "The length of the Hugging Face Dataset is the same as the number of records in the pandas dataframe. For example, there are 800 records in the pandas dataframe for the training dataset, and the length of the converted Hugging Face Dataset for the training dataset is 800 too.\n",
    "\n",
    "`hg_train_data[0]` gives us the first record in the Hugging Face Dataset. It is a dictionary with three keys, `review`, `label`, and `__index_level_0__`.\n",
    "* `review` is the variable name for the review text. The name is inherited from the column name of the pandas dataframe.\n",
    "* `label` is the variable name for the sentiment of the review text. The name is inherited from the column name of the pandas dataframe too.\n",
    "* `__index_level_0__` is an automatically generated field from the pandas dataframe. It stores the index of the corresponding record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tdWpRd5KKqIB",
    "outputId": "06a3be9b-4a4d-44d5-ea09-55b378826178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of hg_train_data is 800.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': 'Thanks again to Amazon for having the things I need for a good price!',\n",
       " 'label': 1,\n",
       " '__index_level_0__': 521}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the Dataset\n",
    "print(f'The length of hg_train_data is {len(hg_train_data)}.\\n')\n",
    "\n",
    "# Check one review\n",
    "hg_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIGEczo3SpYd"
   },
   "source": [
    "In this example, we can see that the review is `Thanks again to Amazon for having the things I need for a good price!`, the sentiment for the review is positive/1, and the index of this record is 521 in the pandas dataframe.\n",
    "\n",
    "Checking the index 521 in the pandas dataframe confirms the same information with Hugging Face Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "uiQBYYZtOJHa",
    "outputId": "113c2a4c-d54f-4f44-ff42-24c36da437d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"amz_review\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Thanks again to Amazon for having the things I need for a good price!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-54a0c147-5cfd-411c-be29-a74a69dac752\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Thanks again to Amazon for having the things I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54a0c147-5cfd-411c-be29-a74a69dac752')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-54a0c147-5cfd-411c-be29-a74a69dac752 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-54a0c147-5cfd-411c-be29-a74a69dac752');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                review  label\n",
       "521  Thanks again to Amazon for having the things I...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the record in pandas dataframe\n",
    "amz_review.iloc[[521]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e596ZDPLB2a5"
   },
   "source": [
    "# Step 5: Tokenize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccd3KQcZwpFN"
   },
   "source": [
    "In step 5, we will tokenize the review text using a tokenizer.\n",
    "\n",
    "A tokenizer converts text into numbers to use as the input of the NLP (Natural Language Processing) models. Each number represents a token, which can be a word, part of a word, punctuation, or special tokens. How the text is tokenized is determined by the pretrained model. `AutoTokenizer.from_pretrained(\"bert-base-cased\")` is used to download vocabulary from the pretrained `bert-base-cased` model, meaning that the text will be tokenized like a BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425,
     "referenced_widgets": [
      "a9548586a4eb439081a1d07fac579bae",
      "4a8d5539433442118ae52833486c1116",
      "69022a734da0484f9cda4a0cb2968871",
      "df44c7e223944a91bd642ae68bc32ddd",
      "ac82ab5e0d124eecb200bac90bd5ab64",
      "03e60573a44048aaa4f2de932c67be4c",
      "717d9a47538148b894a388d66e6b4d3c",
      "7f4a07286e1e42608f0fc7f9d3403f13",
      "6d89a65e571c4917a9970d6ee6a15583",
      "9212245a40d440c4b19481fdc40723cf",
      "ec9364959aac4238a080f38972a37ad9",
      "e27fd15b90aa45459887bea87f3ca935",
      "850d54829ec9471891de94947c46fd53",
      "793d42de613c4f17860ed20821705312",
      "b0bd485ad476430ea4bb21f59919ea56",
      "e5eba77dd55347e69e1378e0f39fac86",
      "f338f6d1cf36450283a8d6ba7ae96a46",
      "2762bc2656fc4365b0df2a93670ad833",
      "8303569e8c744bfbbdde78822bdbf190",
      "3e10e6a6a80a4d5285c8ae051460b577",
      "393493422cc242dfbc3c51d229661a50",
      "5fae76debd9d48e983d6c232a84e41ff",
      "99e8fb875b1f4b39808f3d63a1c1f771",
      "4906b443eb874045819228fec84de3d8",
      "8f1cc0c4171b4c6f88e3e1afe29bffae",
      "e47f268e54a048cd83fd838f018b95ff",
      "92fb81fc8bfb4b8c9b9b0fd399b082e4",
      "6449ddcc0b854534967c7ebb1c0162d0",
      "0c7a183854634f6d9598ee3de9b79c02",
      "044ea5c5dcd347bb810b024af8019ad7",
      "49ce1f5d6b8b4444823597f63eca2350",
      "9dd9e2528b5b4d20b548e8f405dfcc3b",
      "ec3f725d66404349b2952a88cdbf1b51",
      "e1f5aecb0b6f4953a08c204697a82ad1",
      "3833a015e08548fead6a850addd1dcd4",
      "1d657ec30d544faea91e677f69ea4dc0",
      "abe0f348a74241d298fe80e617857150",
      "605a3be8f55b4aa6a515cce2f3dfb4c4",
      "c144f2d733f747cdb5f5fba7052160ed",
      "f6504801d5094b91ad8d3040287fa84f",
      "01ad2fdadba14d6c9de761562e69ccb4",
      "927b84cb971446efbdf7b203feb9dd39",
      "d010867ddaaa4ea38248a819118ff797",
      "74f2e7fb432b4f4f842a4a1719e31da1"
     ]
    },
    "id": "uYVxGawWwsIS",
    "outputId": "3994bfee-a677-4c0c-ea50-0037e64dd0ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9548586a4eb439081a1d07fac579bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27fd15b90aa45459887bea87f3ca935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e8fb875b1f4b39808f3d63a1c1f771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f5aecb0b6f4953a08c204697a82ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer from a pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Take a look at the tokenizer\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFGCx-PWw7yN"
   },
   "source": [
    "We can see that the tokenizer contains information such as model name, vocabulary size, max length, padding position, truncation position, and special tokens.\n",
    "\n",
    "There are five special tokens for the BERT model. Other models may have different special tokens.\n",
    " * The tokens that are not part of the BERT model training dataset are unknown tokens. The unknown token is [UNK] and the ID for the unknown token is 100.\n",
    " * The separator token is [SEP] and the ID for the separator token is 102.\n",
    " * The pad token is [PAD] and the ID for the pad token is 0.\n",
    " * The sentence level classification token is [CLS] and the ID for the classification token is 101.\n",
    " * The mask token is [MASK] and the ID for the mask token is 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "y47m2Z6_wtyU",
    "outputId": "f1acbee2-9a03-484e-b46f-1a8de65255ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unknown token is [UNK] and the ID for the unkown token is 100.\n",
      "The seperator token is [SEP] and the ID for the seperator token is 102.\n",
      "The pad token is [PAD] and the ID for the pad token is 0.\n",
      "The sentence level classification token is [CLS] and the ID for the classification token is 101.\n",
      "The mask token is [MASK] and the ID for the mask token is 103.\n"
     ]
    }
   ],
   "source": [
    "# Mapping between special tokens and their IDs.\n",
    "print(f'The unknown token is {tokenizer.unk_token} and the ID for the unkown token is {tokenizer.unk_token_id}.')\n",
    "print(f'The seperator token is {tokenizer.sep_token} and the ID for the seperator token is {tokenizer.sep_token_id}.')\n",
    "print(f'The pad token is {tokenizer.pad_token} and the ID for the pad token is {tokenizer.pad_token_id}.')\n",
    "print(f'The sentence level classification token is {tokenizer.cls_token} and the ID for the classification token is {tokenizer.cls_token_id}.')\n",
    "print(f'The mask token is {tokenizer.mask_token} and the ID for the mask token is {tokenizer.mask_token_id}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgF67x23W6y2"
   },
   "source": [
    "After downloading the model vocabulary, the method `tokenizer` is used to tokenize the review corpus.\n",
    "* `max_length` indicates the maximum number of tokens kept for each document.\n",
    " * If the document has more tokens than the `max_length`, it will be truncated.\n",
    " * If the document has less tokens than the `max_length`, it will be padded with zeros.\n",
    " * If `max_length` is unset or set to `None`, the maximum length from the pretrained model will be used. If the pretrained model does not have a maximum length parameter, `max_length` will be deactivated.\n",
    "* `truncation` controls how the token truncation is implemented. `truncation=True` indicates that the truncation length is the length specified by `max_length`. If `max_length` is not specified, the max_length of the pretrained model is used.\n",
    "* `padding` means adding zeros to shorter reviews in the dataset. The `padding` argument controls how `padding` is conducted.  \n",
    " * `padding=True` is the same as `padding='longest'`. It checks the longest sequence in the batch and pads zeros to that length. There is no padding if only one text document is provided.\n",
    " * `padding='max_length'` pads to `max_length` if it is specified, otherwise, it pads to the maximum acceptable input length for the model.\n",
    " * `padding=False` is the same as `padding='do_not_pad'`. It is the default, indicating that no padding is applied, so it can output a batch with sequences of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ef0ec05451244ca785b5930aed119c47",
      "e2acb613d1ff41e08fc6cf7da4de3cdb",
      "08a49076dc7b48e19b4db7902a1697f5",
      "3985ad6bc6724611afa6b42e32fd43a7",
      "8b5bda1cbe084a4d938090ee05ff7734",
      "4aa5d2497cc442a4af2826b457af5371",
      "20b980754c4f41be8555529ddffc6ab5",
      "4b8fb8759c9b44a39338f040942d20c9",
      "d3163eb6391648919936652b9a7cad98",
      "c6848aef9f30474289d71cedbb8502bd",
      "f38eec08a8fe4824a006abcd4c050c8a",
      "e562f5689a19409e97caeaddb067af19",
      "de4f1dc215884a08b6e2f2feb75eb327",
      "00f3fdb03a0c44148ab782c90fafb353",
      "b1111343383549b99c45e8dc65a613d7",
      "d683ab33ed084593a6feb403c33f0590",
      "77c09a3c064445769d37b7ed3a519492",
      "2ac6dc2c18244f8ab7e2caf1a3d1069b",
      "58a38e9827d449eb9affd4775b038601",
      "efbaff27803449bbb364cb10fabbce60",
      "e4c6508925db409584bbfa771b7bf6ff",
      "ec05a49523e54be4895f3e359d68feae"
     ]
    },
    "id": "0Pxclwx2qfk9",
    "outputId": "ab8dda18-dbfb-48c3-90e3-9a19e27c2427"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0ec05451244ca785b5930aed119c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e562f5689a19409e97caeaddb067af19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funtion to tokenize data\n",
    "def tokenize_dataset(data):\n",
    "    return tokenizer(data[\"review\"],\n",
    "                     max_length=32,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "dataset_train = hg_train_data.map(tokenize_dataset)\n",
    "dataset_test = hg_test_data.map(tokenize_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7HKyIjbb0Sh"
   },
   "source": [
    "After tokenization, we can see that both the training and the testing Dataset have 6 features, `'review'`, `'label'`, `'__index_level_0__'`, `'input_ids'`, `'token_type_ids'`, and `'attention_mask'`. The number of rows is stored with `num_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "f8b7EQgtoJzH",
    "outputId": "3be56224-b0c6-45d1-b12b-27299982f2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 800\n",
      "})\n",
      "Dataset({\n",
      "    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "print(dataset_train)\n",
    "print(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oan104mCphW7"
   },
   "source": [
    "`dataset_train[0]` gives us the content for the first record in the training dataset in a dictionary format.\n",
    "* `'review'` has the review text. The first review of the training dataset is `'Thanks again to Amazon for having the things I need for a good price!'`.\n",
    "* `'label'` is the label of the classification. The first record is a positive review, so the label is 1.\n",
    "* `'__index_level_0__'` is the index of the record. 521 means that the first record in the training dataset has the index 521 in the original pandas dataframe.\n",
    "* `'input_ids'` are the IDs for the tokens. There are 32 token IDs because the `max_length` is 32 for the tokenization.\n",
    "* `'token_type_ids'` is also called segment IDs.\n",
    " * BERT was trained on two tasks, Masked Language Modeling and Next Sentence Prediction. `'token_type_ids'` is for the Next Sentence Prediction, where two sentences are used to predict whether the second sentence is the next sentence for the first one.\n",
    " * The first sentence has all the tokens represented by zeros, and the second sentence has all the tokens represented by ones.\n",
    " * Because our classification task does not have a second sentence, all the values for `'token_type_ids'` are zeros.\n",
    "* `'attention_mask'` indicates which token ID should get attention from the model, so the padding tokens are all zeros and other tokens are 1s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gCodao7MoQt-",
    "outputId": "042a90fd-b97b-40c6-bf25-26d3fe64f532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'Thanks again to Amazon for having the things I need for a good price!',\n",
       " 'label': 1,\n",
       " '__index_level_0__': 521,\n",
       " 'input_ids': [101,\n",
       "  5749,\n",
       "  1254,\n",
       "  1106,\n",
       "  9786,\n",
       "  1111,\n",
       "  1515,\n",
       "  1103,\n",
       "  1614,\n",
       "  146,\n",
       "  1444,\n",
       "  1111,\n",
       "  170,\n",
       "  1363,\n",
       "  3945,\n",
       "  106,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first record\n",
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pInnpLnyZ0xF"
   },
   "source": [
    "# Step 6: Load Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKw8n6QsnstR"
   },
   "source": [
    "In step 6, we will load the pretrained model for sentiment analysis.\n",
    "\n",
    "* `AutoModelForSequenceClassification` loads the BERT model without the sequence classification head.\n",
    "* The method `from_pretrained()` loads the weights from the pretrained model into the new model, so the weights in the new model are not randomly initialized. Note that the new weights for the new sequence classification head are going to be randomly initialized.\n",
    "* `bert-base-cased` is the name of the pretrained model. We can change it to a different model based on the nature of the project.\n",
    "* `num_labels` indicates the number of classes. Our dataset has two classes, positive and negative, so `num_labels=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "21a70f2085a34acc82aada90f14a7e00",
      "f5752d7e68c74a02b620491b2748c498",
      "41616985a773461e9e39d4a02879ebee",
      "a2db1a6e7e564451835128df25316a1d",
      "fe98ef67f65148e1935bd8d46e5b4af5",
      "3f452c8ea95e4a99b243d0a88b790a7a",
      "2fafb9c99cf24a5981070a2784288237",
      "26a8b53ac0fa48c992de8219458e8957",
      "18418bacd1324cbfa33bdcf1ca362dc5",
      "252d0b8a20e641a6836987474129c405",
      "b143320dca094c3c99e1907ebc913564"
     ]
    },
    "id": "alXwU9ylqGSR",
    "outputId": "a308c8c2-88e9-4677-e810-b9666ebf7e67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a70f2085a34acc82aada90f14a7e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5SRFC8b0QIm"
   },
   "source": [
    "# Step 7: Set Training Argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrTVGiENPznD"
   },
   "source": [
    "In step 7, we will set the training arguments for the model.\n",
    "\n",
    "Hugging Face has 96 parameters for `TrainingArguments`, which provides a lot of flexibility in fine-tuning the transfer learning model.\n",
    "* `output_dir` is the directory to write the model checkpoints and model predictions.\n",
    "* `logging_dir` is the directory for saving logs.\n",
    "* `logging_strategy` is the strategy for logging the training information.\n",
    " * `'no'` means no logging for the training.\n",
    " * `'epoch'` means logging at the end of each epoch.\n",
    " * `'steps'` means logging at the end of each `logging_steps`.\n",
    "* `logging_steps` is the number of steps between two logs. The default is 500.\n",
    "* `num_train_epochs` is the total number of training epochs. The default value is 3.\n",
    "* `per_device_train_batch_size` is the batch size per GPU/TPU core/CPU for training. The default value is 8.\n",
    "* `per_device_eval_batch_size` is the batch size per GPU/TPU core/CPU for evaluation. The default value is 8.\n",
    "* `learning_rate` is the initial learning rate for AdamW optimizer. The default value is 5e-5.\n",
    "* `seed` is for reproducibility.\n",
    "* `save_strategy` is the strategy for saving the checkpoint during training.\n",
    " * `'no'` means do not save during training.\n",
    " * `'epoch'` means saving at the end of each epoch.\n",
    " * `'steps'` means saving at the end of each `save_steps`. `'steps'` is the default value.\n",
    "* `save_steps` is the number of steps before two checkpoint saves. The default value is 500.\n",
    "* `evaluation_strategy` is the strategy for evaluation during training. It's helpful for us to monitor the model performance during model fine-tuning.\n",
    " * `'no'` means no evaluation during training.\n",
    " * `'epoch'` means evaluating at the end of each epoch and the evaluation results will be printed out at the end of each epoch.\n",
    " * `'steps'` means evaluating and reporting at the end of each `eval_steps`. `'no'` is the default value.\n",
    "* `eval_steps` is the number of steps between two evaluations if `evaluation_strategy='steps'`. It defaults to the same value as `logging_steps` if not set.\n",
    "* `load_best_model_at_end=True` indicates that the best model will be loaded at the end of the training. The default is `False`. When it is set to `True`, the `save_strategy` and `evaluation_strategy` must be the same. When both arguments are `'steps'`, the value of `save_steps` needs to be a round multiple of the value of `eval_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aoM8kA7xv61O"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_transfer_learning_transformer/\",\n",
    "    logging_dir='./sentiment_transfer_learning_transformer/logs',\n",
    "    logging_strategy='epoch',\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-6,\n",
    "    seed=42,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=100,\n",
    "    eval_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLAPSRzVNHYH"
   },
   "source": [
    "# Step 8: Set Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz6C-lCncrJb"
   },
   "source": [
    "In step 8, we will set the evaluation metric because Hugging Face Trainer does not evaluate the model performance automatically during the training process.\n",
    "\n",
    "Hugging Face has an `evaluate` library with over 100 evaluation modules. We can see the list of all the modules using `evaluate.list_evaluation_modules()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "X0cir3_DYCkr",
    "outputId": "40e402e2-b914-4035-bfa2-a2b7d4e22d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 216 evaluation models in Hugging Face.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lvwerra/test',\n",
       " 'angelina-wang/directional_bias_amplification',\n",
       " 'cpllab/syntaxgym',\n",
       " 'lvwerra/bary_score',\n",
       " 'hack/test_metric',\n",
       " 'yzha/ctc_eval',\n",
       " 'codeparrot/apps_metric',\n",
       " 'mfumanelli/geometric_mean',\n",
       " 'daiyizheng/valid',\n",
       " 'erntkn/dice_coefficient',\n",
       " 'mgfrantz/roc_auc_macro',\n",
       " 'Vlasta/pr_auc',\n",
       " 'gorkaartola/metric_for_tp_fp_samples',\n",
       " 'idsedykh/metric',\n",
       " 'idsedykh/codebleu2',\n",
       " 'idsedykh/codebleu',\n",
       " 'idsedykh/megaglue',\n",
       " 'Vertaix/vendiscore',\n",
       " 'GMFTBY/dailydialogevaluate',\n",
       " 'GMFTBY/dailydialog_evaluate',\n",
       " 'jzm-mailchimp/joshs_second_test_metric',\n",
       " 'ola13/precision_at_k',\n",
       " 'yulong-me/yl_metric',\n",
       " 'abidlabs/mean_iou',\n",
       " 'abidlabs/mean_iou2',\n",
       " 'KevinSpaghetti/accuracyk',\n",
       " 'NimaBoscarino/weat',\n",
       " 'ronaldahmed/nwentfaithfulness',\n",
       " 'Viona/infolm',\n",
       " 'kyokote/my_metric2',\n",
       " 'kashif/mape',\n",
       " 'Ochiroo/rouge_mn',\n",
       " 'leslyarun/fbeta_score',\n",
       " 'anz2/iliauniiccocrevaluation',\n",
       " 'zbeloki/m2',\n",
       " 'xu1998hz/sescore',\n",
       " 'dvitel/codebleu',\n",
       " 'NCSOFT/harim_plus',\n",
       " 'JP-SystemsX/nDCG',\n",
       " 'sportlosos/sescore',\n",
       " 'Drunper/metrica_tesi',\n",
       " 'jpxkqx/peak_signal_to_noise_ratio',\n",
       " 'jpxkqx/signal_to_reconstruction_error',\n",
       " 'hpi-dhc/FairEval',\n",
       " 'lvwerra/accuracy_score',\n",
       " 'ybelkada/cocoevaluate',\n",
       " 'harshhpareek/bertscore',\n",
       " 'posicube/mean_reciprocal_rank',\n",
       " 'bstrai/classification_report',\n",
       " 'omidf/squad_precision_recall',\n",
       " 'Josh98/nl2bash_m',\n",
       " 'BucketHeadP65/confusion_matrix',\n",
       " 'BucketHeadP65/roc_curve',\n",
       " 'yonting/average_precision_score',\n",
       " 'transZ/test_parascore',\n",
       " 'transZ/sbert_cosine',\n",
       " 'hynky/sklearn_proxy',\n",
       " 'xu1998hz/sescore_english_mt',\n",
       " 'xu1998hz/sescore_german_mt',\n",
       " 'xu1998hz/sescore_english_coco',\n",
       " 'xu1998hz/sescore_english_webnlg',\n",
       " 'unnati/kendall_tau_distance',\n",
       " 'Viona/fuzzy_reordering',\n",
       " 'Viona/kendall_tau',\n",
       " 'lhy/hamming_loss',\n",
       " 'lhy/ranking_loss',\n",
       " 'Muennighoff/code_eval_octopack',\n",
       " 'yuyijiong/quad_match_score',\n",
       " 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics',\n",
       " 'Yeshwant123/mcc',\n",
       " 'phonemetransformers/segmentation_scores',\n",
       " 'sma2023/wil',\n",
       " 'chanelcolgate/average_precision',\n",
       " 'ckb/unigram',\n",
       " 'Felipehonorato/eer',\n",
       " 'manueldeprada/beer',\n",
       " 'shunzh/apps_metric',\n",
       " 'He-Xingwei/sari_metric',\n",
       " 'langdonholmes/cohen_weighted_kappa',\n",
       " 'fschlatt/ner_eval',\n",
       " 'hyperml/balanced_accuracy',\n",
       " 'brian920128/doc_retrieve_metrics',\n",
       " 'guydav/restrictedpython_code_eval',\n",
       " 'k4black/codebleu',\n",
       " 'Natooz/ece',\n",
       " 'ingyu/klue_mrc',\n",
       " 'Vipitis/shadermatch',\n",
       " 'gabeorlanski/bc_eval',\n",
       " 'jjkim0807/code_eval',\n",
       " 'mtc/fragments',\n",
       " 'DarrenChensformer/eval_keyphrase',\n",
       " 'kdudzic/charmatch',\n",
       " 'Vallp/ter',\n",
       " 'DarrenChensformer/relation_extraction',\n",
       " 'Ikala-allen/relation_extraction',\n",
       " 'danieldux/hierarchical_softmax_loss',\n",
       " 'nlpln/tst',\n",
       " 'bdsaglam/jer',\n",
       " 'davebulaval/meaningbert',\n",
       " 'fnvls/bleu1234',\n",
       " 'fnvls/bleu_1234',\n",
       " 'nevikw39/specificity',\n",
       " 'yqsong/execution_accuracy',\n",
       " 'shalakasatheesh/squad_v2',\n",
       " 'arthurvqin/pr_auc',\n",
       " 'd-matrix/dmx_perplexity',\n",
       " 'akki2825/accents_unplugged_eval',\n",
       " 'juliakaczor/accents_unplugged_eval',\n",
       " 'Vickyage/accents_unplugged_eval',\n",
       " 'Qui-nn/accents_unplugged_eval',\n",
       " 'TelEl/accents_unplugged_eval',\n",
       " 'livvie/accents_unplugged_eval',\n",
       " 'DaliaCaRo/accents_unplugged_eval',\n",
       " 'alvinasvk/accents_unplugged_eval',\n",
       " 'LottieW/accents_unplugged_eval',\n",
       " 'sorgfresser/valid_efficiency_score',\n",
       " 'Fritz02/execution_accuracy',\n",
       " 'huanghuayu/multiclass_brier_score',\n",
       " 'jialinsong/apps_metric',\n",
       " 'DoctorSlimm/bangalore_score',\n",
       " 'agkphysics/ccc',\n",
       " 'DoctorSlimm/kaushiks_criteria',\n",
       " 'CZLC/rouge_raw',\n",
       " 'bascobasculino/mot-metrics',\n",
       " 'SEA-AI/mot-metrics',\n",
       " 'SEA-AI/det-metrics',\n",
       " 'saicharan2804/my_metric',\n",
       " 'red1bluelost/evaluate_genericify_cpp',\n",
       " 'maksymdolgikh/seqeval_with_fbeta',\n",
       " 'Bekhouche/NED',\n",
       " 'danieldux/isco_hierarchical_accuracy',\n",
       " 'ginic/phone_errors',\n",
       " 'berkatil/map',\n",
       " 'DarrenChensformer/action_generation',\n",
       " 'buelfhood/fbeta_score',\n",
       " 'danasone/ru_errant',\n",
       " 'helena-balabin/youden_index',\n",
       " 'SEA-AI/panoptic-quality',\n",
       " 'SEA-AI/box-metrics',\n",
       " 'MathewShen/bleu',\n",
       " 'berkatil/mrr',\n",
       " 'BridgeAI-Lab/SemF1',\n",
       " 'SEA-AI/horizon-metrics',\n",
       " 'maysonma/lingo_judge_metric',\n",
       " 'dannashao/span_metric',\n",
       " 'Aye10032/loss_metric',\n",
       " 'ag2435/my_metric',\n",
       " 'kilian-group/arxiv_score',\n",
       " 'bomjin/code_eval_octopack',\n",
       " 'svenwey/logmetric',\n",
       " 'bowdbeg/matching_series',\n",
       " 'BridgeAI-Lab/Sem-nCG',\n",
       " 'bowdbeg/patch_series',\n",
       " 'venkatasg/gleu',\n",
       " 'kbmlcoding/apps_metric',\n",
       " 'jijihuny/ecqa',\n",
       " 'prajwall/mse',\n",
       " 'd-matrix/dmxMetric',\n",
       " 'dotkaio/competition_math',\n",
       " 'bowdbeg/docred',\n",
       " 'Remeris/rouge_ru',\n",
       " 'jarod0411/aucpr',\n",
       " 'Ruchin/jaccard_similarity',\n",
       " 'phucdev/blanc_score',\n",
       " 'NathanMad/bertscore-with-torch_dtype',\n",
       " 'cointegrated/blaser_2_0_qe',\n",
       " 'ahnyeonchan/Alignment-and-Uniformity',\n",
       " 'Baleegh/Fluency_Score',\n",
       " 'mdocekal/multi_label_precision_recall_accuracy_fscore',\n",
       " 'phucdev/vihsd',\n",
       " 'argmaxinc/detailed-wer',\n",
       " 'SEA-AI/user-friendly-metrics',\n",
       " 'hage2000/code_eval_stdio',\n",
       " 'hage2000/my_metric',\n",
       " 'Natooz/levenshtein',\n",
       " 'Khaliq88/execution_accuracy',\n",
       " 'pico-lm/perplexity',\n",
       " 'mtzig/cross_entropy_loss',\n",
       " 'kiracurrie22/precision',\n",
       " 'openpecha/bleurt',\n",
       " 'SEA-AI/ref-metrics',\n",
       " 'Natooz/mse',\n",
       " 'buelfhood/fbeta_score_2',\n",
       " 'murinj/hter',\n",
       " 'pico-lm/blimp',\n",
       " 'nobody4/waf_metric',\n",
       " 'mdocekal/precision_recall_fscore_accuracy',\n",
       " 'Glazkov/mars',\n",
       " 'Aye10032/top5_error_rate',\n",
       " 'nhop/L3Score',\n",
       " 'maryxm/code_eval',\n",
       " 'Usmankiani256/meteor',\n",
       " 'sign/signwriting_similarity',\n",
       " 'maqiuping59/table_markdown',\n",
       " 'aynetdia/semscore',\n",
       " 'Dnfs/awesome_metric',\n",
       " 'AIML-TUDA/VerifiableRewardsForScalableLogicalReasoning',\n",
       " 'LG-Anonym/VerifiableRewardsForScalableLogicalReasoning',\n",
       " 'Bekhouche/ACC',\n",
       " 'sunhill/clip_score',\n",
       " 'sunhill/spice',\n",
       " 'sunhill/cider',\n",
       " 'ncoop57/levenshtein_distance',\n",
       " 'kaleidophon/almost_stochastic_order',\n",
       " 'NeuraFusionAI/Arabic-Evaluation',\n",
       " 'lvwerra/element_count',\n",
       " 'prb977/cooccurrence_count',\n",
       " 'NimaBoscarino/pseudo_perplexity',\n",
       " 'ybelkada/toxicity',\n",
       " 'ronaldahmed/ccl_win',\n",
       " 'christopher/tokens_per_byte',\n",
       " 'lsy641/distinct',\n",
       " 'grepLeigh/perplexity',\n",
       " 'Charles95/element_count',\n",
       " 'Charles95/accuracy',\n",
       " 'Lucky28/honest']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of evaluation modules\n",
    "print(f'There are {len(evaluate.list_evaluation_modules())} evaluation models in Hugging Face.\\n')\n",
    "\n",
    "# List all evaluation metrics\n",
    "evaluate.list_evaluation_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56L2AZe4eroE"
   },
   "source": [
    "Since our dataset is highly balanced, we will use accuracy as the evaluation metric. It can be loaded using `evaluate.load(\"accuracy\")`. After getting predictions from the model, the metric is computed using `metric.compute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Pljt8VLCNJFR"
   },
   "outputs": [],
   "source": [
    "# Function to compute the metric\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    # probabilities = tf.nn.softmax(logits)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2Oxt0KtOqPY"
   },
   "source": [
    "# Step 9: Train Model Using Transformer Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SXRUZ6I1Sq6"
   },
   "source": [
    "In step 9, we will train the model using the transformer `Trainer`.\n",
    "* model is the model for training, evaluation, or prediction by the `Trainer`.\n",
    "* `args` takes the arguments for tweaking the `Trainer`. It defaults to the instance of `TrainingArguments`.\n",
    "* `train_dataset` is the training dataset name. If the dataset is in `Dataset` format, the unused columns will be automatically ignored. In our training dataset, `__index_level_0__` and `review` are not used by the model, so they are ignored.\n",
    "* `eval_dataset` is the evaluation dataset name. Similar to the `train_dataset`, the unused columns will be automatically ignored for the `Dataset` format.\n",
    "* `compute_metrics` takes the function for calculating evaluation metrics.\n",
    "* `callbacks` takes a list of callbacks to customize the training loop. `EarlyStoppingCallback` stops the training by `early_stopping_patience` for the evaluation calls. There is no practical need to use early stopping because there are only two epochs for the model. It is included as an example code reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "53779d9bd3214dc7b89518262fd7d0fe",
      "056d8b12d2144264a388d76d4e2ef472",
      "588841cd2dfe4d4aac3b30c76b9b29a5",
      "7c21f11d394d4f44b0b5810c06264351",
      "fe2c897a32494fbe9ec742e8c1523b0a",
      "046569a67cd743b1ab60eec98ddf9c31",
      "b25ab03bf87b4fd285714cc87f043071",
      "78c3561ced34458c95d412dbb63c418a",
      "7d5513a77ece49ec8e0d1608cf72aa3c",
      "ec4a651c018147c7aab344f2a7a4fb6b",
      "4fe3c4e3c7154d5c8cf3b88ff394b878"
     ]
    },
    "id": "3LHAlFU_6-IF",
    "outputId": "3ee3d03b-5d07-4fc6-d593-e194018c66de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.564900</td>\n",
       "      <td>0.275119</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.214304</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53779d9bd3214dc7b89518262fd7d0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.39739394187927246, metrics={'train_runtime': 57.9379, 'train_samples_per_second': 27.616, 'train_steps_per_second': 6.904, 'total_flos': 26311105536000.0, 'train_loss': 0.39739394187927246, 'epoch': 2.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz5H-O5Y80zK"
   },
   "source": [
    "We can see that the accuracy is above 90 percent in just 2 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqiOoAD-yGKM"
   },
   "source": [
    "# Step 10: Make Predictions for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtXo_gGFgm3F"
   },
   "source": [
    "In step 10, we will talk about how to make predictions using the Hugging Face transformer Trainer model.\n",
    "\n",
    "Passing the tokenized `Dataset` to the `.predict` method, we get the predictions for the customized transfer learning sentiment model. We can see that the prediction results contain multiple pieces of information.\n",
    "* `Num examples = 200` indicates that there are 200 reviews in the testing dataset.\n",
    "* `Batch size = 4` means that 4 reviews are processed each time.\n",
    "* Under `PredictionOutput`, `predictions` has the logits for each class. logit is the last layer of the neural network before softmax is applied. `label_ids` has the actual labels. Please note that it is not predicted labels although it is under the `PredictionOutput`. We need to calculate the predicted labels based on the logit values.\n",
    "* Under `metrics` there is information about the testing predictions.\n",
    " * `test_loss` is the loss for the testing dataset.  \n",
    " * `test_accuracy` is the percentage of correct predictions.\n",
    " * `test_runtime` is the runtime for testing.\n",
    " * `test_samples_per_second` is the number of samples the model can process in one second.\n",
    " * `test_steps_per_second` is the number of steps the model can process in one second.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3643
    },
    "id": "p1jk8PSQgbhS",
    "outputId": "0fdf783b-a99a-4e08-8175-30fe6254b32b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.337913  ,  2.0567882 ],\n",
       "       [-2.0842035 ,  2.1617513 ],\n",
       "       [-2.3695347 ,  2.0440009 ],\n",
       "       [ 1.058769  , -2.0527053 ],\n",
       "       [ 1.1460142 , -2.0395653 ],\n",
       "       [-2.2710783 ,  2.2040794 ],\n",
       "       [ 1.0685357 , -1.8443897 ],\n",
       "       [ 1.0599883 , -2.0149977 ],\n",
       "       [-2.2190018 ,  2.0326715 ],\n",
       "       [ 1.106114  , -2.0032737 ],\n",
       "       [-2.4095082 ,  2.1275632 ],\n",
       "       [ 0.39245996, -1.2386558 ],\n",
       "       [-1.1339428 ,  0.6357692 ],\n",
       "       [-1.5931114 ,  1.2322338 ],\n",
       "       [-2.2777    ,  2.2067661 ],\n",
       "       [ 0.84898484, -1.7747142 ],\n",
       "       [ 0.98557854, -2.139289  ],\n",
       "       [-2.473114  ,  2.2452862 ],\n",
       "       [-2.2006621 ,  2.2210886 ],\n",
       "       [ 1.0887971 , -2.0489047 ],\n",
       "       [-2.2802224 ,  1.9937029 ],\n",
       "       [ 0.33930895, -1.2468055 ],\n",
       "       [-2.4372137 ,  2.188267  ],\n",
       "       [ 1.1117644 , -1.8673589 ],\n",
       "       [-1.6723467 ,  1.1742327 ],\n",
       "       [-2.338886  ,  2.0677106 ],\n",
       "       [ 1.146054  , -1.9198551 ],\n",
       "       [ 1.1817392 , -2.0790927 ],\n",
       "       [-2.4345987 ,  2.313385  ],\n",
       "       [ 0.958627  , -1.9010783 ],\n",
       "       [-1.4200267 ,  0.9012983 ],\n",
       "       [ 1.0532063 , -2.0642974 ],\n",
       "       [-2.3388426 ,  1.9590987 ],\n",
       "       [-0.09412946, -0.6120832 ],\n",
       "       [ 0.96847683, -1.926862  ],\n",
       "       [-2.0860982 ,  2.057087  ],\n",
       "       [ 1.1912302 , -2.053391  ],\n",
       "       [ 0.3203969 , -1.2938364 ],\n",
       "       [-2.341088  ,  2.309232  ],\n",
       "       [ 0.6507914 , -1.8793344 ],\n",
       "       [-2.334003  ,  2.1855254 ],\n",
       "       [-2.0898209 ,  1.9402999 ],\n",
       "       [-2.405065  ,  2.3981185 ],\n",
       "       [-2.3672643 ,  2.1607976 ],\n",
       "       [-2.2886188 ,  2.2035282 ],\n",
       "       [-2.2466512 ,  1.8418996 ],\n",
       "       [-2.3838892 ,  1.9816238 ],\n",
       "       [ 0.9936797 , -1.9974349 ],\n",
       "       [ 1.0549542 , -2.0127492 ],\n",
       "       [ 1.0439967 , -2.0254762 ],\n",
       "       [ 1.1422895 , -1.9936231 ],\n",
       "       [ 1.0520091 , -1.9644824 ],\n",
       "       [ 1.1604723 , -2.0400274 ],\n",
       "       [-2.416966  ,  2.086041  ],\n",
       "       [-2.5615997 ,  2.264952  ],\n",
       "       [-2.1309934 ,  2.1128333 ],\n",
       "       [ 0.86269194, -1.9813826 ],\n",
       "       [-2.1125345 ,  1.7970601 ],\n",
       "       [ 1.1233459 , -2.0041847 ],\n",
       "       [ 1.1786337 , -2.0518525 ],\n",
       "       [-2.4701273 ,  2.0700748 ],\n",
       "       [-2.4647539 ,  2.216734  ],\n",
       "       [-2.021783  ,  1.5171838 ],\n",
       "       [ 1.0073361 , -2.0024276 ],\n",
       "       [-2.2823453 ,  1.909359  ],\n",
       "       [ 1.1078781 , -1.7581923 ],\n",
       "       [ 1.1395904 , -2.0053508 ],\n",
       "       [-2.246331  ,  2.2901206 ],\n",
       "       [-1.4473096 ,  0.82019055],\n",
       "       [ 1.0031654 , -1.9301596 ],\n",
       "       [-2.422186  ,  2.3424776 ],\n",
       "       [-2.195445  ,  1.9688504 ],\n",
       "       [ 1.138824  , -1.9971927 ],\n",
       "       [ 0.9747632 , -1.9371636 ],\n",
       "       [-2.3261287 ,  2.0312576 ],\n",
       "       [-2.2483842 ,  2.2330332 ],\n",
       "       [ 0.88649434, -1.6757387 ],\n",
       "       [-2.4582005 ,  2.2696912 ],\n",
       "       [-2.1395087 ,  2.1748374 ],\n",
       "       [-2.1855078 ,  2.1007504 ],\n",
       "       [ 0.66617346, -1.8059872 ],\n",
       "       [-0.13918395, -0.7625657 ],\n",
       "       [ 1.0089059 , -2.0123737 ],\n",
       "       [ 0.9968685 , -1.9298598 ],\n",
       "       [ 0.8518286 , -1.8607026 ],\n",
       "       [ 1.0815953 , -2.1086125 ],\n",
       "       [ 1.0341833 , -1.9181014 ],\n",
       "       [-2.3185782 ,  2.1882246 ],\n",
       "       [ 1.1010286 , -1.9399958 ],\n",
       "       [ 1.0046682 , -2.0492377 ],\n",
       "       [-1.8650316 ,  1.308728  ],\n",
       "       [ 0.8801762 , -1.7699008 ],\n",
       "       [ 1.1150019 , -2.0385032 ],\n",
       "       [-1.1870477 ,  0.6953827 ],\n",
       "       [-2.3473616 ,  2.2528496 ],\n",
       "       [ 1.1612265 , -1.9492395 ],\n",
       "       [-2.4067297 ,  2.0925126 ],\n",
       "       [ 0.9076141 , -1.9764044 ],\n",
       "       [-2.5535872 ,  2.1640823 ],\n",
       "       [-2.4147925 ,  2.3160725 ],\n",
       "       [ 0.90996045, -2.002518  ],\n",
       "       [ 0.9557747 , -1.9336812 ],\n",
       "       [-2.427309  ,  2.1140244 ],\n",
       "       [-1.3891915 ,  0.9298685 ],\n",
       "       [-2.4577827 ,  2.2348256 ],\n",
       "       [ 1.094761  , -1.9899399 ],\n",
       "       [-2.4492826 ,  2.2500777 ],\n",
       "       [-2.4294138 ,  2.1551461 ],\n",
       "       [ 0.99566007, -1.9618837 ],\n",
       "       [-2.386104  ,  2.2814922 ],\n",
       "       [ 0.14462583, -0.9582851 ],\n",
       "       [-2.395377  ,  2.3353508 ],\n",
       "       [ 1.1870621 , -2.0731466 ],\n",
       "       [ 0.82219887, -1.6145629 ],\n",
       "       [-2.4803798 ,  2.209681  ],\n",
       "       [ 0.99386984, -1.8854105 ],\n",
       "       [ 1.0472083 , -2.0620673 ],\n",
       "       [ 0.975217  , -2.0573575 ],\n",
       "       [ 1.0848973 , -1.8237218 ],\n",
       "       [-1.8740649 ,  1.759555  ],\n",
       "       [ 0.35717097, -0.98537666],\n",
       "       [ 1.0318747 , -1.8961759 ],\n",
       "       [-2.311273  ,  2.1461225 ],\n",
       "       [-1.6448139 ,  1.0486704 ],\n",
       "       [-2.2433715 ,  1.6352913 ],\n",
       "       [ 0.8546635 , -2.11717   ],\n",
       "       [ 1.1007996 , -2.028606  ],\n",
       "       [-2.3897665 ,  2.0996015 ],\n",
       "       [-2.047256  ,  2.205763  ],\n",
       "       [ 1.1469414 , -1.9155117 ],\n",
       "       [-2.3520594 ,  2.1921353 ],\n",
       "       [-2.4831636 ,  2.1181483 ],\n",
       "       [ 1.0209515 , -2.0957708 ],\n",
       "       [-1.3859649 ,  0.80242693],\n",
       "       [-2.1934066 ,  2.171325  ],\n",
       "       [ 1.0785499 , -1.8431648 ],\n",
       "       [ 1.1956387 , -2.0181725 ],\n",
       "       [ 1.0254163 , -1.9595473 ],\n",
       "       [-1.8223976 ,  1.5275992 ],\n",
       "       [ 1.0493724 , -1.935025  ],\n",
       "       [ 1.0192708 , -1.9031526 ],\n",
       "       [-2.2538111 ,  1.9668235 ],\n",
       "       [ 1.1300501 , -1.8725326 ],\n",
       "       [ 0.33283478, -1.2136047 ],\n",
       "       [-2.3220913 ,  2.2060156 ],\n",
       "       [-1.0721272 ,  0.68055993],\n",
       "       [-2.5357578 ,  2.074688  ],\n",
       "       [ 0.9345573 , -1.8654929 ],\n",
       "       [ 0.4919239 , -1.1725339 ],\n",
       "       [-2.3878748 ,  2.088747  ],\n",
       "       [ 1.1557078 , -2.087397  ],\n",
       "       [-2.4447808 ,  2.0180354 ],\n",
       "       [ 1.197015  , -1.9818454 ],\n",
       "       [ 1.1423795 , -2.0040116 ],\n",
       "       [ 0.85020673, -1.9621694 ],\n",
       "       [-2.0813313 ,  2.2367332 ],\n",
       "       [-2.2981207 ,  1.8503875 ],\n",
       "       [ 0.9254856 , -1.8960067 ],\n",
       "       [ 1.0694898 , -2.1089847 ],\n",
       "       [-2.0366397 ,  2.1411276 ],\n",
       "       [-2.1611378 ,  2.1970594 ],\n",
       "       [ 1.0731373 , -2.0870705 ],\n",
       "       [ 0.8810555 , -1.8696547 ],\n",
       "       [-0.83240056,  0.15588832],\n",
       "       [-2.2663305 ,  2.1549976 ],\n",
       "       [-2.1809897 ,  2.1815157 ],\n",
       "       [-2.5837774 ,  2.304991  ],\n",
       "       [ 1.1207725 , -2.0446436 ],\n",
       "       [-2.262072  ,  1.8190145 ],\n",
       "       [ 1.1092112 , -1.9128978 ],\n",
       "       [ 1.1721413 , -2.0032804 ],\n",
       "       [-2.2031772 ,  2.1738727 ],\n",
       "       [ 0.9686438 , -1.9345033 ],\n",
       "       [ 0.91217613, -1.9914118 ],\n",
       "       [ 1.1489508 , -1.9427061 ],\n",
       "       [ 1.0431923 , -2.077517  ],\n",
       "       [ 1.0941006 , -2.005473  ],\n",
       "       [ 1.097599  , -2.0216076 ],\n",
       "       [ 1.151129  , -1.9539251 ],\n",
       "       [-1.7337451 ,  1.1501542 ],\n",
       "       [ 0.72416747, -1.6244624 ],\n",
       "       [-2.4685123 ,  2.2901518 ],\n",
       "       [-2.2175136 ,  2.127928  ],\n",
       "       [ 1.0657334 , -1.987769  ],\n",
       "       [ 1.2148577 , -1.9707918 ],\n",
       "       [ 0.91917795, -2.0523849 ],\n",
       "       [ 1.1884577 , -2.035011  ],\n",
       "       [ 0.50090075, -1.325903  ],\n",
       "       [ 0.9948236 , -1.9423987 ],\n",
       "       [ 0.77097636, -1.6384816 ],\n",
       "       [-2.403137  ,  2.1649668 ],\n",
       "       [ 1.1424673 , -2.0597806 ],\n",
       "       [ 1.0774236 , -2.0986156 ],\n",
       "       [-2.116418  ,  2.1415033 ],\n",
       "       [-1.5324647 ,  1.1448578 ],\n",
       "       [ 0.54524094, -1.6695642 ],\n",
       "       [ 1.0092574 , -1.8631296 ],\n",
       "       [ 0.6739537 , -1.2753406 ],\n",
       "       [ 0.862016  , -1.721326  ],\n",
       "       [ 0.9990399 , -2.1318982 ]], dtype=float32), label_ids=array([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0]), metrics={'test_loss': 0.21430419385433197, 'test_accuracy': 0.93, 'test_runtime': 1.0891, 'test_samples_per_second': 183.642, 'test_steps_per_second': 45.911})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_test_predict = trainer.predict(dataset_test)\n",
    "\n",
    "# Take a look at the predictions\n",
    "y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9y3EfeO-8yN"
   },
   "source": [
    "The predicted logits for the transfer learning text classification model can be extracted using `.predictions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmcAlpnl_hJF"
   },
   "source": [
    "We can see that the prediction has two columns. The first column is the predicted logit for label 0 and the second column is the predicted logit for label 1. logit values do not sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "N_HSPkZAminc",
    "outputId": "cbf4177c-7060-467c-bd1a-576ee6c9ea55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.337913 ,  2.0567882],\n",
       "       [-2.0842035,  2.1617513],\n",
       "       [-2.3695347,  2.0440009],\n",
       "       [ 1.058769 , -2.0527053],\n",
       "       [ 1.1460142, -2.0395653]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted logits\n",
    "y_test_logits = y_test_predict.predictions\n",
    "\n",
    "# First 5 predicted probabilities\n",
    "y_test_logits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge6rXFhY_kGc"
   },
   "source": [
    "To get the predicted probabilities, we need to apply softmax on the predicted logit values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU5JrMyZ_0GY"
   },
   "source": [
    "After applying softmax, we can see that the predicted probability for each review sums up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ow4uX4Jv_srX",
    "outputId": "f7fa742b-d648-4ef4-cb1a-5f539998609b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.01219209, 0.9878079 ],\n",
       "       [0.01411983, 0.9858802 ],\n",
       "       [0.01196733, 0.9880327 ],\n",
       "       [0.95736355, 0.04263642],\n",
       "       [0.960288  , 0.03971201]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities\n",
    "y_test_probabilities = tf.nn.softmax(y_test_logits)\n",
    "\n",
    "# First 5 predicted logits\n",
    "y_test_probabilities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyFbba9R_7ko"
   },
   "source": [
    "To get the predicted labels, `argmax` is used to return the index of the maximum probability for each review, which corresponds to the labels of zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "1I0mQBmO4drn",
    "outputId": "e1fccfb1-eecf-4a90-bda3-1bd92dfb3765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted labels\n",
    "y_test_pred_labels = np.argmax(y_test_probabilities, axis=1)\n",
    "\n",
    "# First 5 predicted probabilities\n",
    "y_test_pred_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBkMRVTx_-pT"
   },
   "source": [
    "The actual labels can be extracted using `y_test_predict.label_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bOdI273Xmt9_",
    "outputId": "45bc65c6-1f51-4e75-9b53-f25d42327f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual labels\n",
    "y_test_actual_labels = y_test_predict.label_ids\n",
    "\n",
    "# First 5 predicted probabilities\n",
    "y_test_actual_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBhVxzzNqn13"
   },
   "source": [
    "# Step 11: Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4jmMaJbAK7K"
   },
   "source": [
    "In step 11, we will make the transfer learning text classification model performance evaluation.\n",
    "\n",
    "`trainer.evaluate` is a quick way to get the loss and the accuracy of the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gj7Sr1lCD3T"
   },
   "source": [
    "We can see that the model has a loss of 0.28 and an accuracy of 91.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "0S8AKdc2Bm0Q",
    "outputId": "d4355b61-d226-4e61-b87c-2c658b6fea72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21430419385433197,\n",
       " 'eval_accuracy': 0.93,\n",
       " 'eval_runtime': 0.9603,\n",
       " 'eval_samples_per_second': 208.277,\n",
       " 'eval_steps_per_second': 52.069,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer evaluate\n",
    "trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__cIM_jjCT3x"
   },
   "source": [
    "To calculate more model performance metrics, we can use `evaluate.load` to load the metrics of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-X-JB4Qlcbs"
   },
   "source": [
    "The results show that the testing dataset has a `f1` value of 0.91 and a `recall` value of 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "aeee4304e7684e6f983e52bba9e1129b",
      "00ca23e882a04c7394289926d9a00e73",
      "c18417766c704957ba2f33da99157d81",
      "5607ce3b377047e496e4485827717cd8",
      "45526489bd4d4b8a9cb0f5f11e06f390",
      "267a693340a943ec931ef381c7d4759c",
      "6c1231adb76c4480b829cd1e3ab5c3ac",
      "7ec310571e4c40faa914c887dd7e3af3",
      "fd146b7c293742069894f270e661acd7",
      "0ce9fb2946a74fcbb5d3256c9e059caf",
      "aa6ad15372c84165a2842f2c0eb4d3a7"
     ]
    },
    "id": "VaeNxx0l4rpk",
    "outputId": "1ad779a1-9dbe-4303-ce7b-fe734280c6d2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeee4304e7684e6f983e52bba9e1129b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9263157894736842}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load f1 metric\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "# Compute f1 metric\n",
    "metric_f1.compute(predictions=y_test_pred_labels, references=y_test_actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "5f1fb97e83454bb486f06ac3f7db6c88",
      "d5d3098cfb5b4f01822adfc41d07601c",
      "28e4f4576d8348fd92846060f1227fc3",
      "b4cb374717854a73a89cb3c4116dee71",
      "dc9b2eda24bc4587bca075d78fe6c643",
      "409c36f8e06b4f5887cadc21cc56a522",
      "fc1aa380c15840eca647d82a19a57120",
      "029ad69de8b24430a3e490b3f116e9e3",
      "9488dec93e494582821ee6fb822499db",
      "d98965efb46e4156bca0d975f68d74bf",
      "60078afb49694287b68500e3350dc913"
     ]
    },
    "id": "x_jMEh-wrn00",
    "outputId": "a41ec382-1709-4d13-a5e1-048dd7b35e2a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1fb97e83454bb486f06ac3f7db6c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8877551020408163}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load recall metric\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "# Compute recall metric\n",
    "metric_recall.compute(predictions=y_test_pred_labels, references=y_test_actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33BZbt5FwTL0"
   },
   "source": [
    "# Step 12: Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI54T7SWSEKv"
   },
   "source": [
    "In step 12, we will talk about how to save the model and reload it for prediction.\n",
    "\n",
    "`tokenizer.save_pretrained` saves the tokenizer information to the drive and `model.save_model` saves the model to the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "phvsc3K47X-c"
   },
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./sentiment_transfer_learning_transformer/')\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./sentiment_transfer_learning_transformer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH2KqgCXSxcc"
   },
   "source": [
    "We can load the saved tokenizer later using `AutoTokenizer.from_pretrained()` and load the saved model using `AutoModelForSequenceClassification.from_pretrained()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "rTSztSdeYwnP"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_transfer_learning_transformer/\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained('./sentiment_transfer_learning_transformer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlaxpewffvtc"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_hOgTMtfyl0"
   },
   "source": [
    "* [Hugging Face documentation on fine-tuning a pretrained model](https://huggingface.co/docs/transformers/training)\n",
    "* [Hugging Face notebook on fine-tuning a pretrained model](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)\n",
    "* [Hugging Face documentation on tokenizer](https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html)\n",
    "* [Deeplearning.AI transfer learning video from Andrew Ng](https://www.youtube.com/watch?v=yofjFQddwHE)\n",
    "* [Hugging Face TensorFlow predictions and metrics video](https://youtu.be/nx10eh4CoOs)\n",
    "* [Hugging Face documentation on prepare_tf_dataset()](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)\n",
    "* [Hugging Face documentation on transformers.Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)\n",
    "* [Hugging Face documentation on Datasets](https://huggingface.co/docs/datasets/v1.7.0/index.html#:~:text=Datasets%20and%20evaluation%20metrics%20for,Natural%20Language%20Processing%20(NLP).)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
